{
    "ollama adapter settings": "Adapter settings for Ollama",
    "Ollama Server IP": "Ollama Server IP",
    "Ollama Server Port": "Ollama Server Port",
    "Check if Ollama model is running": "Check if Ollama model is running",
    "Timer to check if the Ollama model is running. Set to 0 to disable.": "Timer to check if the Ollama model is running. Set to 0 to disable.",
    "Ollama Models": "Ollama Models",
    "Response": "Response",
    "Running": "Running",
    "Expires": "Expires",
    "Messages": "Messages",
    "Role": "Role",
    "Content": "Content",
    "Images (JSON Array)": "Images (JSON Array)",
    "Tool Calls (JSON Array)": "Tool Calls (JSON Array)",
    "Stream": "Stream",
    "Think": "Think",
    "Tools (JSON)": "Tools (JSON)",
    "Keep Alive": "Keep Alive",
    "Format ('json' or JSON object)": "Format ('json' or JSON object)",
    "Options (JSON)": "Options (JSON)",
    "Info": "Info",
    "Connection status": "Connection status",
    "Description": "Description",
    "Units": "Units",
    "Value for TRUE (Boolean)": "Value for TRUE (Boolean)",
    "Value for FALSE (Boolean)": "Value for FALSE (Boolean)",
    "Location": "Location",
    "Data type": "Data type",
    "Select the data type for this datapoint": "Select the data type for this datapoint",
    "Additional text": "Additional text",
    "Additional text for text type": "Additional text for text type",
    "Use Qdrant": "Use Qdrant",
    "Qdrant Server IP": "Qdrant Server IP",
    "Qdrant Server Port": "Qdrant Server Port",
    "Database": "Database",
    "Enable Datapoint Control": "Enable Datapoint Control",
    "Allow AI models to automatically change datapoints based on their responses (e.g., 'Martin ist jetzt anwesend').": "Allow AI models to automatically change datapoints based on their responses (e.g., 'Martin ist jetzt anwesend').",
    "Control": "Control",
    "Embedding Model": "Embedding Model",
    "Max Context Results": "Max Context Results",
    "Allow automatic state changes": "Allow automatic state changes",
    "Boolean": "Boolean",
    "Number": "Number",
    "Text": "Text",
    "Vector Database": "Banco de dados vetorial",
    "Clean up duplicates": "Limpe as duplicatas",
    "Processing": "Processamento",
    "Response Content": "Conteúdo de resposta",
    "Connection": "Conexão",
    "IP address or hostname of the direct Ollama server (for status monitoring).": "Endereço IP ou nome do host do servidor Ollama Direct (para monitoramento de status).",
    "Port of the direct Ollama server (default: 11434).": "Porta do servidor Ollama Direct (padrão: 11434).",
    "OpenWebUI Server IP": "OpenWebui Server IP",
    "IP address or hostname of the OpenWebUI server.": "Endereço IP ou nome do host do servidor OpenWebui.",
    "OpenWebUI Server Port": "Porta do servidor OpenWebui",
    "Port of the OpenWebUI server.": "Porta do servidor OpenWebui.",
    "OpenWebUI API Key": "Chave da API OpenWebui",
    "API Key for OpenWebUI authentication (Bearer Token). Get it from Settings > Account in OpenWebUI.": "Chave da API para autenticação OpenWebui (Token do portador). Obtenha -o nas configurações> Conta no OpenWebui.",
    "Check model status interval": "Verifique o intervalo de status do modelo",
    "Timer to check model availability via direct Ollama connection. Set to 0 to disable.": "Timer para verificar a disponibilidade do modelo via conexão de Ollama direta. Definido como 0 para desativar.",
    "Use Qdrant as vector database for Ollama.": "Use QDRANT como banco de dados vetorial para Ollama.",
    "IP address or hostname of the Qdrant server.": "Endereço IP ou nome do host do servidor QDRANT.",
    "Port of the Qdrant server.": "Porta do servidor QDRANT.",
    "Model to use for generating embeddings.": "Modelo a ser usado para gerar incorporações.",
    "Maximum number of context results to include in queries.": "Número máximo de resultados de contexto a serem incluídos nas consultas.",
    "Function Calling": "Chamada de função",
    "Allow AI models to control ioBroker datapoints via function calls.": "Permita que os modelos de IA controlem o IOBROKer DataPoints por meio de chamadas de função.",
    "If enabled, AI models can automatically change this datapoint's value based on their responses.": "Se ativado, os modelos de IA podem alterar automaticamente o valor desse DataPoint com base em suas respostas.",
    "Select the data type for this datapoint.": "Selecione o tipo de dados para este projeto de dados.",
    "Description of the datapoint.": "Descrição do ponto de dados.",
    "Location of the datapoint.": "Localização do ponto de dados.",
    "Unit of the value (e.g. °C, %, etc.)": "Unidade do valor (por exemplo, ° C, %, etc.)",
    "Value used for TRUE.": "Valor usado para verdadeiro.",
    "Value used for FALSE.": "Valor usado para false.",
    "Additional text for text type.": "Texto adicional para o tipo de texto.",
    "Original Model Name": "Nome do modelo original",
    "Temperature": "Temperatura",
    "Controls randomness in AI responses (0.0 = deterministic, 1.0 = very creative)": "Controla a aleatoriedade nas respostas da IA (0,0 = determinista, 1.0 = muito criativo)",
    "Max Tokens": "Tokens máximos",
    "Maximum number of tokens in AI response": "Número máximo de tokens na resposta da IA",
    "Automatic Control Whitelist": "Controle automático Whitelist",
    "Whitelist of command patterns that trigger automatic datapoint control. Use * as wildcard. Separate patterns with | (pipe). Only messages matching these patterns will trigger commands.": "Lista de permissões de padrões de comando que acionam o controle automático do DataPoint. Use * como curinga. Padrões separados com | (cano). Somente mensagens correspondentes a esses padrões desencadearão comandos.",
    "intent_control_detected": "Intenção de controle detectada",
    "intent_info_detected": "Solicitação de informações detectadas",
    "intent_no_intent": "Nenhuma intenção reconhecida",
    "intent_scene_detected": "Ação de cena detectada",
    "intent_confidence_low": "Intenção de confiança muito baixa",
    "datapoint_set_success": "Defina com sucesso {{DataPoint}} como {{value}}",
    "datapoint_set_failed": "Falha ao definir {{DataPoint}}: {{error}}",
    "datapoint_not_allowed": "DataPoint {{DataPoint}} não permitido para controle automático",
    "datapoint_type_conversion_failed": "Tipo de conversão falhou para {{value}} para {{type}}",
    "datapoint_boolean_true": "verdadeiro",
    "datapoint_boolean_false": "falso",
    "datapoint_invalid_type": "Tipo de dados inválido: {{type}}",
    "learning_action_recorded": "Ação gravada para {{DataPoint}}",
    "learning_scene_created": "Cena criada \"{{name}}\" com {{count}} DataPoints",
    "learning_association_learned": "Associação aprendida entre {{primário}} e {{parceira}}",
    "learning_data_saved": "Dados de aprendizado salvos",
    "learning_data_loaded": "Dados de aprendizado carregados com {{count}} associações",
    "server_starting": "SERVER DE TOLAS DE CONFIGURA ...",
    "server_started": "ToolServer começou com sucesso na porta {{porta}}",
    "server_failed_start": "Falhou ao iniciar o SERVER: {{Error}}",
    "server_stopping": "Sofping ToolServer ...",
    "server_stopped": "ToolServer parou",
    "server_already_running": "ToolServer já está em execução",
    "server_chat_processed": "Solicitação de bate -papo processado com sucesso",
    "server_intent_processed": "Solicitação de intenção processada",
    "vectordb_connection_ok": "Conexão de banco de dados vetorial bem -sucedida",
    "vectordb_connection_failed": "Falha na conexão do banco de dados vetorial: {{error}}",
    "vectordb_embedding_generated": "Incorporação gerada para {{text}}",
    "vectordb_data_stored": "Dados armazenados no banco de dados vetorial",
    "vectordb_duplicates_cleaned": "Limpo {{count}} entradas duplicadas",
    "vectordb_search_completed": "Pesquisa vetorial concluída com {{count}} resultados",
    "llm_response_generated": "LLM Resposta gerada",
    "llm_request_failed": "Solicitação LLM falhou: {{error}}",
    "llm_model_unavailable": "Modelo LLM indisponível",
    "llm_intent_analysis_complete": "Análise de intenções LLM completa",
    "llm_fallback_parsing": "Usando a análise de fallback para a resposta LLM",
    "llm_fallback_pattern": "Detector LLM voltando à detecção de padrões",
    "llm_error": "LLM detection error: {{error}}",
    "llm_configured": "Detector LLM configurado",
    "llm_unavailable": "Llm indisponível: {{error}}",
    "general_initialized": "{{componente}} inicializado com sucesso",
    "general_configuration_updated": "Configuração atualizada",
    "general_error_occurred": "Ocorreu o erro: {{error}}",
    "general_operation_complete": "Operação concluída",
    "general_invalid_input": "Entrada inválida: {{input}}",
    "general_not_available": "{{recurso}} não está disponível"
}
