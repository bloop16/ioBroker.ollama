{
    "ollama adapter settings": "Ajustes del adaptador para ollama",
    "Ollama Server IP": "IP del servidor Ollama",
    "Ollama Server Port": "Puerto de servidor Ollama",
    "Check if Ollama model is running": "Compruebe si el modelo Ollama se está ejecutando",
    "Timer to check if the Ollama model is running. Set to 0 to disable.": "Temporizador para verificar si el modelo Ollama se está ejecutando. Establecido en 0 para deshabilitar.",
    "Ollama Models": "Modelos Ollama",
    "Response": "Respuesta",
    "Running": "Ejecutándose",
    "Expires": "Caduca",
    "Messages": "Mensajes",
    "Role": "Rol",
    "Content": "Contenido",
    "Images (JSON Array)": "Imágenes (matriz JSON)",
    "Tool Calls (JSON Array)": "Llamadas de herramientas (matriz JSON)",
    "Stream": "Flujo",
    "Think": "Pensar",
    "Tools (JSON)": "Herramientas (JSON)",
    "Keep Alive": "Mantener activo",
    "Format ('json' or JSON object)": "Formato ('JSON' o objeto JSON)",
    "Options (JSON)": "Opciones (JSON)",
    "Info": "Información",
    "Connection status": "Estado de conexión",
    "Description": "Descripción",
    "Units": "Unidades",
    "Value for TRUE (Boolean)": "Valor para VERDADERO (Boolean)",
    "Value for FALSE (Boolean)": "Valor para FALSO (Boolean)",
    "Location": "Ubicación",
    "Data type": "Tipo de datos",
    "Select the data type for this datapoint": "Seleccione el tipo de datos para este punto de datos",
    "Additional text": "Texto adicional",
    "Additional text for text type": "Texto adicional para el tipo de texto",
    "Use Qdrant": "Usar Qdrant",
    "Qdrant Server IP": "IP del servidor Qdrant",
    "Qdrant Server Port": "Puerto de servidor Qdrant",
    "Database": "Base de datos",
    "Enable Datapoint Control": "Habilitar control de punto de datos",
    "Allow AI models to automatically change datapoints based on their responses (e.g., 'Martin ist jetzt anwesend').": "Permitir que los modelos de IA cambien automáticamente los puntos de datos basándose en sus respuestas (ej., 'Martin está ahora presente').",
    "Control": "Control",
    "Embedding Model": "Modelo de incrustación",
    "Max Context Results": "Resultados máximos de contexto",
    "Allow automatic state changes": "Permitir cambios automáticos de estado",
    "Boolean": "Booleano",
    "Number": "Número",
    "Text": "Texto",
    "Vector Database": "Base de datos vectorial",
    "Clean up duplicates": "Limpiar los duplicados",
    "Processing": "Tratamiento",
    "Response Content": "Contenido de respuesta",
    "Connection": "Conexión",
    "IP address or hostname of the direct Ollama server (for status monitoring).": "Dirección IP o nombre de host del servidor Ollama directo (para monitoreo de estado).",
    "Port of the direct Ollama server (default: 11434).": "Puerto del servidor Ollama directo (predeterminado: 11434).",
    "OpenWebUI Server IP": "IP del servidor OpenWebui",
    "IP address or hostname of the OpenWebUI server.": "Dirección IP o nombre de host del servidor OpenWebui.",
    "OpenWebUI Server Port": "Puerto de servidor OpenWebui",
    "Port of the OpenWebUI server.": "Puerto del servidor OpenWebui.",
    "OpenWebUI API Key": "Llave de API de OpenWebui",
    "API Key for OpenWebUI authentication (Bearer Token). Get it from Settings > Account in OpenWebUI.": "Clave API para la autenticación OpenWebui (token de portador). Obtenga desde Configuración> Cuenta en OpenWebui.",
    "Check model status interval": "Verifique el intervalo de estado del modelo",
    "Timer to check model availability via direct Ollama connection. Set to 0 to disable.": "Temporizador para verificar la disponibilidad del modelo a través de la conexión Ollama directa. Establecido en 0 para deshabilitar.",
    "Use Qdrant as vector database for Ollama.": "Use Qdrant como base de datos vectorial para Ollama.",
    "IP address or hostname of the Qdrant server.": "Dirección IP o nombre de host del servidor Qdrant.",
    "Port of the Qdrant server.": "Puerto del servidor Qdrant.",
    "Model to use for generating embeddings.": "Modelo para usar para generar incrustaciones.",
    "Maximum number of context results to include in queries.": "Número máximo de resultados de contexto para incluir en consultas.",
    "Function Calling": "Funciones llamadas",
    "Allow AI models to control ioBroker datapoints via function calls.": "Permita que los modelos AI controlen los puntos de datos de IOBROKER a través de llamadas de funciones.",
    "If enabled, AI models can automatically change this datapoint's value based on their responses.": "Si está habilitado, los modelos AI pueden cambiar automáticamente el valor de este punto de datos en función de sus respuestas.",
    "Select the data type for this datapoint.": "Seleccione el tipo de datos para este punto de datos.",
    "Description of the datapoint.": "Descripción del punto de datos.",
    "Location of the datapoint.": "Ubicación del punto de datos.",
    "Unit of the value (e.g. °C, %, etc.)": "Unidad del valor (por ejemplo, ° C, %, etc.)",
    "Value used for TRUE.": "Valor utilizado para verdadero.",
    "Value used for FALSE.": "Valor utilizado para falso.",
    "Additional text for text type.": "Texto adicional para el tipo de texto.",
    "Original Model Name": "Nombre del modelo original",
    "Temperature": "Temperatura",
    "Controls randomness in AI responses (0.0 = deterministic, 1.0 = very creative)": "Controla la aleatoriedad en las respuestas de IA (0.0 = determinista, 1.0 = muy creativo)",
    "Max Tokens": "Tokens Max",
    "Maximum number of tokens in AI response": "Número máximo de tokens en respuesta de IA",
    "Automatic Control Whitelist": "Control automático Whitelist",
    "Whitelist of command patterns that trigger automatic datapoint control. Use * as wildcard. Separate patterns with | (pipe). Only messages matching these patterns will trigger commands.": "La lista blanca de patrones de comando que activan el control automático de punto de datos. Use * como comodín. Patrones separados con | (tubo). Solo los mensajes que coinciden con estos patrones activarán comandos.",
    "intent_control_detected": "Intención de control detectada",
    "intent_info_detected": "Solicitud de información detectada",
    "intent_no_intent": "Sin intención reconocida",
    "intent_scene_detected": "Acción de escena detectada",
    "intent_confidence_low": "Intención Confianza demasiado baja",
    "datapoint_set_success": "Establecer correctamente {{datapoint}} a {{value}}",
    "datapoint_set_failed": "No se pudo establecer {{dataPoint}}: {{Error}}",
    "datapoint_not_allowed": "DataPoint {{dataPoint}} no permitido para el control automático",
    "datapoint_type_conversion_failed": "La conversión de tipo falló para {{valor}} a {{tipo}}",
    "datapoint_boolean_true": "verdadero",
    "datapoint_boolean_false": "FALSO",
    "datapoint_invalid_type": "Tipo de datos no válido: {{tipo}}",
    "learning_action_recorded": "Acción registrada para {{dataPoint}}",
    "learning_scene_created": "Escena creada \"{{name}}\" con {{Count}} DataPoints",
    "learning_association_learned": "Asociación aprendida entre {{primario}} y {{socio}}",
    "learning_data_saved": "Datos de aprendizaje guardados",
    "learning_data_loaded": "Aprender datos cargados con {{count}} asociaciones",
    "server_starting": "Inicio de herramientas de herramientas ...",
    "server_started": "Toolserver comenzó con éxito en el puerto {{puerto}}",
    "server_failed_start": "No se pudo iniciar herramientas: {{error}}",
    "server_stopping": "Detener las herramientas de herramientas ...",
    "server_stopped": "Toolingerver se detuvo",
    "server_already_running": "Toolingerver ya en ejecución",
    "server_chat_processed": "Solicitud de chat procesada correctamente",
    "server_intent_processed": "Solicitud de intención procesada",
    "vectordb_connection_ok": "Conexión de base de datos vectorial exitosa",
    "vectordb_connection_failed": "Falló la conexión de la base de datos de vector: {{error}}",
    "vectordb_embedding_generated": "Incrustación generada para {{text}}",
    "vectordb_data_stored": "Datos almacenados en la base de datos Vector",
    "vectordb_duplicates_cleaned": "Limpiado {{count}} entradas duplicadas",
    "vectordb_search_completed": "Búsqueda vectorial completada con {{count}} resultados",
    "llm_response_generated": "Respuesta de LLM generada",
    "llm_request_failed": "Falló la solicitud de LLM: {{error}}",
    "llm_model_unavailable": "Modelo LLM no disponible",
    "llm_intent_analysis_complete": "LLM Análisis de intención completo",
    "llm_fallback_parsing": "Usar un análisis de respaldo para la respuesta LLM",
    "llm_fallback_pattern": "Detector LLM Regreso a la detección de patrones",
    "llm_error": "Error de detección LLM: {{error}}",
    "llm_configured": "Detector LLM configurado",
    "llm_unavailable": "LLM no disponible: {{error}}",
    "general_initialized": "{{componente}} inicializado correctamente",
    "general_configuration_updated": "Configuración actualizada",
    "general_error_occurred": "Ocurrió un error: {{error}}",
    "general_operation_complete": "Operación completada",
    "general_invalid_input": "Entrada no válida: {{entrada}}",
    "general_not_available": "{{característica}} no disponible"
}
