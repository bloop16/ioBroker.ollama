{
    "ollama adapter settings": "Paramètres d'adaptateur pour ollama",
    "Ollama Server IP": "IP du serveur Ollama",
    "Ollama Server Port": "Port de serveur Ollama",
    "Check if Ollama model is running": "Vérifiez si le modèle Ollama est en cours d'exécution",
    "Timer to check if the Ollama model is running. Set to 0 to disable.": "Timer pour vérifier si le modèle Ollama est en cours d'exécution. Réglé sur 0 pour désactiver.",
    "Ollama Models": "Modèles Ollama",
    "Response": "Réponse",
    "Running": "En cours d'exécution",
    "Expires": "Expire",
    "Messages": "Messages",
    "Role": "Rôle",
    "Content": "Contenu",
    "Images (JSON Array)": "Images (Array JSON)",
    "Tool Calls (JSON Array)": "Appels d'outils (tableau JSON)",
    "Stream": "Flux",
    "Think": "Penser",
    "Tools (JSON)": "Outils (JSON)",
    "Keep Alive": "Rester en vie",
    "Format ('json' or JSON object)": "Format ('json' ou objet JSON)",
    "Options (JSON)": "Options (JSON)",
    "Info": "Informations",
    "Connection status": "État de connexion",
    "Description": "Description",
    "Units": "Unités",
    "Value for TRUE (Boolean)": "Valeur pour VRAI (Boolean)",
    "Value for FALSE (Boolean)": "Valeur pour FAUX (Boolean)",
    "Location": "Emplacement",
    "Data type": "Type de données",
    "Select the data type for this datapoint": "Sélectionnez le type de données pour ce point de données",
    "Additional text": "Texte supplémentaire",
    "Additional text for text type": "Texte supplémentaire pour le type de texte",
    "Use Qdrant": "Utiliser Qdrant",
    "Qdrant Server IP": "IP du serveur Qdrant",
    "Qdrant Server Port": "Port de serveur Qdrant",
    "Database": "Base de données",
    "Enable Datapoint Control": "Activer le contrôle des points de données",
    "Allow AI models to automatically change datapoints based on their responses (e.g., 'Martin ist jetzt anwesend').": "Permettre aux modèles IA de changer automatiquement les points de données basés sur leurs réponses (par ex., 'Martin est maintenant présent').",
    "Control": "Contrôle",
    "Embedding Model": "Modèle d'intégration",
    "Max Context Results": "Résultats de contexte maximum",
    "Allow automatic state changes": "Permettre les changements d'état automatiques",
    "Boolean": "Booléen",
    "Number": "Nombre",
    "Text": "Texte",
    "Vector Database": "Base de données vectorielle",
    "Clean up duplicates": "Nettoyer les doublons",
    "Processing": "Traitement",
    "Response Content": "Contenu de réponse",
    "Connection": "Connexion",
    "IP address or hostname of the direct Ollama server (for status monitoring).": "Adresse IP ou nom d'hôte du serveur Ollama direct (pour la surveillance de l'état).",
    "Port of the direct Ollama server (default: 11434).": "Port du serveur Ollama direct (par défaut: 11434).",
    "OpenWebUI Server IP": "IP du serveur OpenWebui Open",
    "IP address or hostname of the OpenWebUI server.": "Adresse IP ou nom d'hôte du serveur OpenWebui.",
    "OpenWebUI Server Port": "Port de serveur OpenWebui",
    "Port of the OpenWebUI server.": "Port du serveur OpenWebui.",
    "OpenWebUI API Key": "Clé API OpenWebui",
    "API Key for OpenWebUI authentication (Bearer Token). Get it from Settings > Account in OpenWebUI.": "Clé API pour l'authentification OpenWebui (Token Bearer). Obtenez-le à partir des paramètres> Compte dans OpenWebui.",
    "Check model status interval": "Vérifier l'intervalle d'état du modèle",
    "Timer to check model availability via direct Ollama connection. Set to 0 to disable.": "Timer pour vérifier la disponibilité du modèle via la connexion directe Olllama. Réglé sur 0 pour désactiver.",
    "Use Qdrant as vector database for Ollama.": "Utilisez QDRANT comme base de données vectorielle pour Ollama.",
    "IP address or hostname of the Qdrant server.": "Adresse IP ou nom d'hôte du serveur QDrant.",
    "Port of the Qdrant server.": "Port du serveur QDrant.",
    "Model to use for generating embeddings.": "Modèle à utiliser pour générer des intérêts.",
    "Maximum number of context results to include in queries.": "Nombre maximum de résultats de contexte à inclure dans les requêtes.",
    "Function Calling": "Fonction d'appel",
    "Allow AI models to control ioBroker datapoints via function calls.": "Permettez aux modèles AI de contrôler les points de données IOBRoker via des appels de fonction.",
    "If enabled, AI models can automatically change this datapoint's value based on their responses.": "S'ils sont activés, les modèles AI peuvent modifier automatiquement la valeur de ce DataPoint en fonction de leurs réponses.",
    "Select the data type for this datapoint.": "Sélectionnez le type de données pour ce point de données.",
    "Description of the datapoint.": "Description du point de données.",
    "Location of the datapoint.": "Emplacement du point de données.",
    "Unit of the value (e.g. °C, %, etc.)": "Unité de la valeur (par exemple ° C,%, etc.)",
    "Value used for TRUE.": "Valeur utilisée pour true.",
    "Value used for FALSE.": "Valeur utilisée pour false.",
    "Additional text for text type.": "Texte supplémentaire pour le type de texte.",
    "Original Model Name": "Nom du modèle original",
    "Temperature": "Température",
    "Controls randomness in AI responses (0.0 = deterministic, 1.0 = very creative)": "Contrôle le caractère aléatoire dans les réponses d'IA (0,0 = déterministe, 1,0 = très créatif)",
    "Max Tokens": "Jetons max",
    "Maximum number of tokens in AI response": "Nombre maximum de jetons dans la réponse IA",
    "Automatic Control Whitelist": "Liste blanche de contrôle automatique",
    "Whitelist of command patterns that trigger automatic datapoint control. Use * as wildcard. Separate patterns with | (pipe). Only messages matching these patterns will trigger commands.": "Liste blanche des modèles de commande qui déclenchent un contrôle automatique du point de données. Utiliser * comme joker. Des modèles séparés avec | (tuyau). Seuls les messages correspondant à ces modèles déclenchent des commandes.",
    "intent_control_detected": "Intention de contrôle détectée",
    "intent_info_detected": "Demande d'informations détectée",
    "intent_no_intent": "Aucune intention reconnue",
    "intent_scene_detected": "Action de scène détectée",
    "intent_confidence_low": "Confiance en intention trop faible",
    "datapoint_set_success": "Définir avec succès {{datapoint}} vers {{valeur}}",
    "datapoint_set_failed": "Échec de définir {{datapoint}}: {{error}}",
    "datapoint_not_allowed": "DataPoint {{dataPoint}} Non autorisé pour le contrôle automatique",
    "datapoint_type_conversion_failed": "La conversion de type a échoué pour {{valeur}} en {{type}}",
    "datapoint_boolean_true": "vrai",
    "datapoint_boolean_false": "FAUX",
    "datapoint_invalid_type": "Type de données non valide: {{type}}",
    "learning_action_recorded": "Action enregistrée pour {{datapoint}}",
    "learning_scene_created": "Scène créée \"{{nom}}\" avec {{count}} points de données",
    "learning_association_learned": "Association apprise entre {{primaire}} et {{partenaire}}",
    "learning_data_saved": "Apprentissage des données enregistrées",
    "learning_data_loaded": "Apprentissage des données chargées avec des associations {{count}}",
    "server_starting": "SERVICURS DE TELLEMENT ...",
    "server_started": "Toolerver a commencé avec succès sur le port {{port}}",
    "server_failed_start": "Échec du démarrage de Tooler: {{error}}",
    "server_stopping": "STOPPORT TOOLSERVER ...",
    "server_stopped": "Tooler Server s'est arrêté",
    "server_already_running": "Server à outils est déjà en cours d'exécution",
    "server_chat_processed": "Demande de chat traitée avec succès",
    "server_intent_processed": "Demande d'intention traitée",
    "vectordb_connection_ok": "Connexion de la base de données vectorielle réussie",
    "vectordb_connection_failed": "La connexion de la base de données vectorielle a échoué: {{error}}",
    "vectordb_embedding_generated": "Intégration générée pour {{text}}",
    "vectordb_data_stored": "Données stockées dans la base de données vectorielle",
    "vectordb_duplicates_cleaned": "Nettoyée {{count}} entrées en double",
    "vectordb_search_completed": "Recherche de vecteur terminée avec {{count}} Résultats",
    "llm_response_generated": "Réponse LLM générée",
    "llm_request_failed": "La demande LLM a échoué: {{error}}",
    "llm_model_unavailable": "Modèle LLM indisponible",
    "llm_intent_analysis_complete": "Analyse de l'intention LLM complète",
    "llm_fallback_parsing": "Utilisation de l'analyse de secours pour la réponse LLM",
    "llm_fallback_pattern": "Détecteur LLM retombant à la détection de motifs",
    "llm_error": "Erreur de détection LLM: {{erreur}}",
    "llm_configured": "Détecteur LLM configuré",
    "llm_unavailable": "Llm indisponible: {{error}}",
    "general_initialized": "{{composant}} initialisé avec succès",
    "general_configuration_updated": "Configuration mise à jour",
    "general_error_occurred": "Une erreur s'est produite: {{error}}",
    "general_operation_complete": "Opération terminée",
    "general_invalid_input": "Entrée non valide: {{entrée}}",
    "general_not_available": "{{fonctionnalité}} non disponible"
}
