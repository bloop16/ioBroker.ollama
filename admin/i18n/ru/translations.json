{
    "ollama adapter settings": "Adapter settings for Ollama",
    "Ollama Server IP": "Ollama Server IP",
    "Ollama Server Port": "Ollama Server Port",
    "Check if Ollama model is running": "Check if Ollama model is running",
    "Timer to check if the Ollama model is running. Set to 0 to disable.": "Timer to check if the Ollama model is running. Set to 0 to disable.",
    "Ollama Models": "Ollama Models",
    "Response": "Response",
    "Running": "Running",
    "Expires": "Expires",
    "Messages": "Messages",
    "Role": "Role",
    "Content": "Content",
    "Images (JSON Array)": "Images (JSON Array)",
    "Tool Calls (JSON Array)": "Tool Calls (JSON Array)",
    "Stream": "Stream",
    "Think": "Think",
    "Tools (JSON)": "Tools (JSON)",
    "Keep Alive": "Keep Alive",
    "Format ('json' or JSON object)": "Format ('json' or JSON object)",
    "Options (JSON)": "Options (JSON)",
    "Info": "Info",
    "Connection status": "Connection status",
    "Description": "Description",
    "Units": "Units",
    "Value for TRUE (Boolean)": "Value for TRUE (Boolean)",
    "Value for FALSE (Boolean)": "Value for FALSE (Boolean)",
    "Location": "Location",
    "Data type": "Data type",
    "Select the data type for this datapoint": "Select the data type for this datapoint",
    "Additional text": "Additional text",
    "Additional text for text type": "Additional text for text type",
    "Use Qdrant": "Use Qdrant",
    "Qdrant Server IP": "Qdrant Server IP",
    "Qdrant Server Port": "Qdrant Server Port",
    "Database": "Database",
    "Enable Datapoint Control": "Enable Datapoint Control",
    "Allow AI models to automatically change datapoints based on their responses (e.g., 'Martin ist jetzt anwesend').": "Allow AI models to automatically change datapoints based on their responses (e.g., 'Martin ist jetzt anwesend').",
    "Control": "Control",
    "Embedding Model": "Embedding Model",
    "Max Context Results": "Max Context Results",
    "Allow automatic state changes": "Allow automatic state changes",
    "Boolean": "Boolean",
    "Number": "Number",
    "Text": "Text",
    "Vector Database": "Векторная база данных",
    "Clean up duplicates": "Очистите дубликаты",
    "Processing": "Обработка",
    "Response Content": "Содержание ответа",
    "Connection": "Связь",
    "IP address or hostname of the direct Ollama server (for status monitoring).": "IP -адрес или имя хоста прямого сервера Ollama (для мониторинга состояния).",
    "Port of the direct Ollama server (default: 11434).": "Порт Direct Ollama Server (по умолчанию: 11434).",
    "OpenWebUI Server IP": "OpenWebui Server IP",
    "IP address or hostname of the OpenWebUI server.": "IP -адрес или имя хоста сервера OpenWebui.",
    "OpenWebUI Server Port": "OpenWebui Server Port",
    "Port of the OpenWebUI server.": "Порт сервера OpenWebui.",
    "OpenWebUI API Key": "OpenWebui API -ключ",
    "API Key for OpenWebUI authentication (Bearer Token). Get it from Settings > Account in OpenWebUI.": "Ключ API для аутентификации OpenWebui (токен носителя). Получите его из настройки> учетной записи в OpenWebui.",
    "Check model status interval": "Проверьте интервал состояния модели",
    "Timer to check model availability via direct Ollama connection. Set to 0 to disable.": "Таймер, чтобы проверить доступность модели через прямое соединение Ollama. Установить на 0, чтобы отключить.",
    "Use Qdrant as vector database for Ollama.": "Используйте Qdrant в качестве векторной базы данных для Ollama.",
    "IP address or hostname of the Qdrant server.": "IP -адрес или имя хоста сервера Qdrant.",
    "Port of the Qdrant server.": "Порт Qdrant Server.",
    "Model to use for generating embeddings.": "Модель для использования для генерации встраиваний.",
    "Maximum number of context results to include in queries.": "Максимальное количество контекста приводит к включению в запросы.",
    "Function Calling": "Функция вызова",
    "Allow AI models to control ioBroker datapoints via function calls.": "Позвольте моделям ИИ управлять DABROKER DATAPOINT через вызовы функций.",
    "If enabled, AI models can automatically change this datapoint's value based on their responses.": "Если включено, модели искусственного интеллекта могут автоматически изменять значение этого данных на основе их ответов.",
    "Select the data type for this datapoint.": "Выберите тип данных для этого данных.",
    "Description of the datapoint.": "Описание данных.",
    "Location of the datapoint.": "Расположение данных.",
    "Unit of the value (e.g. °C, %, etc.)": "Единица значения (например, ° C, %и т. Д.)",
    "Value used for TRUE.": "Значение, используемое для True.",
    "Value used for FALSE.": "Значение, используемое для false.",
    "Additional text for text type.": "Дополнительный текст для типа текста.",
    "Original Model Name": "Оригинальное название модели",
    "Temperature": "Температура",
    "Controls randomness in AI responses (0.0 = deterministic, 1.0 = very creative)": "Контролирует случайность в ответах AI (0,0 = детерминированный, 1,0 = очень творческий)",
    "Max Tokens": "Макс. Токены",
    "Maximum number of tokens in AI response": "Максимальное количество токенов в ответе ИИ",
    "Automatic Control Whitelist": "Автоматический управление белым списком",
    "Whitelist of command patterns that trigger automatic datapoint control. Use * as wildcard. Separate patterns with | (pipe). Only messages matching these patterns will trigger commands.": "Белый список командных шаблонов, которые запускают автоматическое управление датой датой. Используйте * в качестве подстановочного знака. Отдельные шаблоны с | (трубка). Только сообщения, соответствующие этим шаблонам, будут запускать команды.",
    "intent_control_detected": "Обнаружено контроль",
    "intent_info_detected": "Информационный запрос обнаружен",
    "intent_no_intent": "Не распознается намерения",
    "intent_scene_detected": "Действие сцены обнаружено",
    "intent_confidence_low": "Намерен уверенность",
    "datapoint_set_success": "Успешно установить {{datapoint}} на {{value}}",
    "datapoint_set_failed": "Не удалось установить {{datapoint}}: {{erry}}",
    "datapoint_not_allowed": "DataPoint {{datapoint}} не разрешен для автоматического управления",
    "datapoint_type_conversion_failed": "Тип преобразования не удалось для {{value}} to {{type}}",
    "datapoint_boolean_true": "истинный",
    "datapoint_boolean_false": "ЛОЖЬ",
    "datapoint_invalid_type": "Неверный тип данных: {{type}}",
    "learning_action_recorded": "Записано действие для {{datapoint}}",
    "learning_scene_created": "Созданная сцена \"{{name}}\" с {{count}} datapoints",
    "learning_association_learned": "Ученый ассоциация между {{primary}} и {{partner}}",
    "learning_data_saved": "Данные обучения сохранены",
    "learning_data_loaded": "Учебные данные, загруженные {{count}} ассоциаций",
    "server_starting": "Начало инструментов ...",
    "server_started": "Toolserver успешно начался на порте {{port}}",
    "server_failed_start": "Не удалось запустить Toolserver: {{error}}",
    "server_stopping": "Остановка инструментов ...",
    "server_stopped": "Toolserver остановился",
    "server_already_running": "Toolserver уже работает",
    "server_chat_processed": "Запрос в чате успешно обработан",
    "server_intent_processed": "Запрос намерения обработана",
    "vectordb_connection_ok": "Подключение к векторной базе данных успешно",
    "vectordb_connection_failed": "Сбой подключения к базе данных вектор: {{error}}",
    "vectordb_embedding_generated": "Встроение, сгенерированное для {{text}}",
    "vectordb_data_stored": "Данные, хранящиеся в векторной базе данных",
    "vectordb_duplicates_cleaned": "Очищен {{count}} дубликаты записей",
    "vectordb_search_completed": "Векторный поиск завершен с {{count}} результатами",
    "llm_response_generated": "Сгенерированный ответ LLM",
    "llm_request_failed": "Ошибка запроса LLM: {{error}}",
    "llm_model_unavailable": "Модель LLM недоступна",
    "llm_intent_analysis_complete": "Анализ намерений LLM завершен",
    "llm_fallback_parsing": "Использование резервного анализа для ответа LLM",
    "llm_fallback_pattern": "Детектор LLM возвращается к обнаружению рисунка",
    "llm_error": "Ошибка обнаружения LLM: {{error}}",
    "llm_configured": "Detector LLM настроен",
    "llm_unavailable": "Llm novailable: {{error}}",
    "general_initialized": "{{компонент}} инициализирован успешно",
    "general_configuration_updated": "Конфигурация обновлена",
    "general_error_occurred": "Произошла ошибка: {{ошибка}}",
    "general_operation_complete": "Операция завершена",
    "general_invalid_input": "Неверный ввод: {{input}}",
    "general_not_available": "{{функция}} недоступен"
}
