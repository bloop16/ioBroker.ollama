{
    "ollama adapter settings": "Adapter settings for Ollama",
    "Ollama Server IP": "Ollama Server IP",
    "Ollama Server Port": "Ollama Server Port",
    "Check if Ollama model is running": "Check if Ollama model is running",
    "Timer to check if the Ollama model is running. Set to 0 to disable.": "Timer to check if the Ollama model is running. Set to 0 to disable.",
    "Ollama Models": "Ollama Models",
    "Response": "Response",
    "Running": "Running",
    "Expires": "Expires",
    "Messages": "Messages",
    "Role": "Role",
    "Content": "Content",
    "Images (JSON Array)": "Images (JSON Array)",
    "Tool Calls (JSON Array)": "Tool Calls (JSON Array)",
    "Stream": "Stream",
    "Think": "Think",
    "Tools (JSON)": "Tools (JSON)",
    "Keep Alive": "Keep Alive",
    "Format ('json' or JSON object)": "Format ('json' or JSON object)",
    "Options (JSON)": "Options (JSON)",
    "Info": "Info",
    "Connection status": "Connection status",
    "Description": "Description",
    "Units": "Units",
    "Value for TRUE (Boolean)": "Value for TRUE (Boolean)",
    "Value for FALSE (Boolean)": "Value for FALSE (Boolean)",
    "Location": "Location",
    "Data type": "Data type",
    "Select the data type for this datapoint": "Select the data type for this datapoint",
    "Additional text": "Additional text",
    "Additional text for text type": "Additional text for text type",
    "Use Qdrant": "Use Qdrant",
    "Qdrant Server IP": "Qdrant Server IP",
    "Qdrant Server Port": "Qdrant Server Port",
    "Database": "Database",
    "Enable Datapoint Control": "Enable Datapoint Control",
    "Allow AI models to automatically change datapoints based on their responses (e.g., 'Martin ist jetzt anwesend').": "Allow AI models to automatically change datapoints based on their responses (e.g., 'Martin ist jetzt anwesend').",
    "Control": "Control",
    "Embedding Model": "Embedding Model",
    "Max Context Results": "Max Context Results",
    "Allow automatic state changes": "Allow automatic state changes",
    "Boolean": "Boolean",
    "Number": "Number",
    "Text": "Text",
    "Vector Database": "Baza danych wektorowych",
    "Clean up duplicates": "Oczyść duplikaty",
    "Processing": "Przetwarzanie",
    "Response Content": "Zawartość odpowiedzi",
    "Connection": "Połączenie",
    "IP address or hostname of the direct Ollama server (for status monitoring).": "Adres IP lub nazwa hosta bezpośredniego serwera Ollama (do monitorowania statusu).",
    "Port of the direct Ollama server (default: 11434).": "Port bezpośredniego serwera Ollama (domyślnie: 11434).",
    "OpenWebUI Server IP": "OpenWebui Server IP",
    "IP address or hostname of the OpenWebUI server.": "Adres IP lub nazwa hosta serwera OpenWebui.",
    "OpenWebUI Server Port": "Port serwera OpenWebui",
    "Port of the OpenWebUI server.": "Port serwera OpenWebui.",
    "OpenWebUI API Key": "Klucz API OpenWebui",
    "API Key for OpenWebUI authentication (Bearer Token). Get it from Settings > Account in OpenWebUI.": "Klucz API do uwierzytelniania OpenWebui (token nosiciel). Zdobądź go z ustawień> Konto w OpenWebui.",
    "Check model status interval": "Sprawdź interwał statusu modelu",
    "Timer to check model availability via direct Ollama connection. Set to 0 to disable.": "Timer Aby sprawdzić dostępność modelu za pomocą bezpośredniego połączenia Ollama. Ustaw na 0, aby wyłączyć.",
    "Use Qdrant as vector database for Ollama.": "Użyj QDRANT jako bazy danych wektorowych dla Ollamy.",
    "IP address or hostname of the Qdrant server.": "Adres IP lub nazwa hosta serwera QDRANT.",
    "Port of the Qdrant server.": "Port serwera QDRANT.",
    "Model to use for generating embeddings.": "Model do generowania osadzonych.",
    "Maximum number of context results to include in queries.": "Maksymalna liczba wyników kontekstu, które należy uwzględnić w zapytaniach.",
    "Function Calling": "Wywołanie funkcji",
    "Allow AI models to control ioBroker datapoints via function calls.": "Pozwól, aby modele AI kontrolować punkty danych IOBRoker za pomocą wywołań funkcji.",
    "If enabled, AI models can automatically change this datapoint's value based on their responses.": "Jeśli są włączone, modele AI mogą automatycznie zmienić wartość tego punktu danych na podstawie ich odpowiedzi.",
    "Select the data type for this datapoint.": "Wybierz typ danych dla tego punktu danych.",
    "Description of the datapoint.": "Opis punktu danych.",
    "Location of the datapoint.": "Lokalizacja punktu danych.",
    "Unit of the value (e.g. °C, %, etc.)": "Jednostka wartości (np. ° C, %itp.)",
    "Value used for TRUE.": "Wartość używana dla True.",
    "Value used for FALSE.": "Wartość używana dla fałszu.",
    "Additional text for text type.": "Dodatkowy tekst dla typu tekstu.",
    "Original Model Name": "Oryginalna nazwa modelu",
    "Temperature": "Temperatura",
    "Controls randomness in AI responses (0.0 = deterministic, 1.0 = very creative)": "Kontroluje losowość w odpowiedzi AI (0,0 = deterministyczne, 1,0 = bardzo kreatywne)",
    "Max Tokens": "Max tokeny",
    "Maximum number of tokens in AI response": "Maksymalna liczba tokenów w odpowiedzi AI"
}
