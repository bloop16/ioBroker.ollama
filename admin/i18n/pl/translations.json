{
    "ollama adapter settings": "Adapter settings for Ollama",
    "Ollama Server IP": "Ollama Server IP",
    "Ollama Server Port": "Ollama Server Port",
    "Check if Ollama model is running": "Check if Ollama model is running",
    "Timer to check if the Ollama model is running. Set to 0 to disable.": "Timer to check if the Ollama model is running. Set to 0 to disable.",
    "Ollama Models": "Ollama Models",
    "Response": "Response",
    "Running": "Running",
    "Expires": "Expires",
    "Messages": "Messages",
    "Role": "Role",
    "Content": "Content",
    "Images (JSON Array)": "Images (JSON Array)",
    "Tool Calls (JSON Array)": "Tool Calls (JSON Array)",
    "Stream": "Stream",
    "Think": "Think",
    "Tools (JSON)": "Tools (JSON)",
    "Keep Alive": "Keep Alive",
    "Format ('json' or JSON object)": "Format ('json' or JSON object)",
    "Options (JSON)": "Options (JSON)",
    "Info": "Info",
    "Connection status": "Connection status",
    "Description": "Description",
    "Units": "Units",
    "Value for TRUE (Boolean)": "Value for TRUE (Boolean)",
    "Value for FALSE (Boolean)": "Value for FALSE (Boolean)",
    "Location": "Location",
    "Data type": "Data type",
    "Select the data type for this datapoint": "Select the data type for this datapoint",
    "Additional text": "Additional text",
    "Additional text for text type": "Additional text for text type",
    "Use Qdrant": "Use Qdrant",
    "Qdrant Server IP": "Qdrant Server IP",
    "Qdrant Server Port": "Qdrant Server Port",
    "Database": "Database",
    "Enable Datapoint Control": "Enable Datapoint Control",
    "Allow AI models to automatically change datapoints based on their responses (e.g., 'Martin ist jetzt anwesend').": "Allow AI models to automatically change datapoints based on their responses (e.g., 'Martin ist jetzt anwesend').",
    "Control": "Control",
    "Embedding Model": "Embedding Model",
    "Max Context Results": "Max Context Results",
    "Allow automatic state changes": "Allow automatic state changes",
    "Boolean": "Boolean",
    "Number": "Number",
    "Text": "Text",
    "Vector Database": "Baza danych wektorowych",
    "Clean up duplicates": "Oczyść duplikaty",
    "Processing": "Przetwarzanie",
    "Response Content": "Zawartość odpowiedzi",
    "Connection": "Połączenie",
    "IP address or hostname of the direct Ollama server (for status monitoring).": "Adres IP lub nazwa hosta bezpośredniego serwera Ollama (do monitorowania statusu).",
    "Port of the direct Ollama server (default: 11434).": "Port bezpośredniego serwera Ollama (domyślnie: 11434).",
    "OpenWebUI Server IP": "OpenWebui Server IP",
    "IP address or hostname of the OpenWebUI server.": "Adres IP lub nazwa hosta serwera OpenWebui.",
    "OpenWebUI Server Port": "Port serwera OpenWebui",
    "Port of the OpenWebUI server.": "Port serwera OpenWebui.",
    "OpenWebUI API Key": "Klucz API OpenWebui",
    "API Key for OpenWebUI authentication (Bearer Token). Get it from Settings > Account in OpenWebUI.": "Klucz API do uwierzytelniania OpenWebui (token nosiciel). Zdobądź go z ustawień> Konto w OpenWebui.",
    "Check model status interval": "Sprawdź interwał statusu modelu",
    "Timer to check model availability via direct Ollama connection. Set to 0 to disable.": "Timer Aby sprawdzić dostępność modelu za pomocą bezpośredniego połączenia Ollama. Ustaw na 0, aby wyłączyć.",
    "Use Qdrant as vector database for Ollama.": "Użyj QDRANT jako bazy danych wektorowych dla Ollamy.",
    "IP address or hostname of the Qdrant server.": "Adres IP lub nazwa hosta serwera QDRANT.",
    "Port of the Qdrant server.": "Port serwera QDRANT.",
    "Model to use for generating embeddings.": "Model do generowania osadzonych.",
    "Maximum number of context results to include in queries.": "Maksymalna liczba wyników kontekstu, które należy uwzględnić w zapytaniach.",
    "Function Calling": "Wywołanie funkcji",
    "Allow AI models to control ioBroker datapoints via function calls.": "Pozwól, aby modele AI kontrolować punkty danych IOBRoker za pomocą wywołań funkcji.",
    "If enabled, AI models can automatically change this datapoint's value based on their responses.": "Jeśli są włączone, modele AI mogą automatycznie zmienić wartość tego punktu danych na podstawie ich odpowiedzi.",
    "Select the data type for this datapoint.": "Wybierz typ danych dla tego punktu danych.",
    "Description of the datapoint.": "Opis punktu danych.",
    "Location of the datapoint.": "Lokalizacja punktu danych.",
    "Unit of the value (e.g. °C, %, etc.)": "Jednostka wartości (np. ° C, %itp.)",
    "Value used for TRUE.": "Wartość używana dla True.",
    "Value used for FALSE.": "Wartość używana dla fałszu.",
    "Additional text for text type.": "Dodatkowy tekst dla typu tekstu.",
    "Original Model Name": "Oryginalna nazwa modelu",
    "Temperature": "Temperatura",
    "Controls randomness in AI responses (0.0 = deterministic, 1.0 = very creative)": "Kontroluje losowość w odpowiedzi AI (0,0 = deterministyczne, 1,0 = bardzo kreatywne)",
    "Max Tokens": "Max tokeny",
    "Maximum number of tokens in AI response": "Maksymalna liczba tokenów w odpowiedzi AI",
    "Automatic Control Whitelist": "Automatyczna białej białej kontroli",
    "Whitelist of command patterns that trigger automatic datapoint control. Use * as wildcard. Separate patterns with | (pipe). Only messages matching these patterns will trigger commands.": "Whitelist wzorców poleceń, które wyzwala automatyczne sterowanie punktem danych. Użyj * jako wieloznaczny. Oddzielne wzory z | (rura). Tylko komunikaty dopasowane do tych wzorców wywołują polecenia.",
    "intent_control_detected": "Wykryto zamiar kontroli",
    "intent_info_detected": "Wykryto żądanie informacji",
    "intent_no_intent": "Brak uznania",
    "intent_scene_detected": "Wykryto akcję sceny",
    "intent_confidence_low": "Zbyt niskie zaufanie",
    "datapoint_set_success": "Pomyślnie ustaw {{DataPoint}} na {{wartość}}",
    "datapoint_set_failed": "Nie udało się ustawić {{dataPoint}}: {{error}}",
    "datapoint_not_allowed": "DataPoint {{DataPoint}} Niedozwolone do automatycznej kontroli",
    "datapoint_type_conversion_failed": "Wpisz konwersję nie powiodła się dla {{wartość}} do {{type}}",
    "datapoint_boolean_true": "PRAWDA",
    "datapoint_boolean_false": "FAŁSZ",
    "datapoint_invalid_type": "Niepoprawny typ danych: {{typ}}",
    "learning_action_recorded": "Nagrane działanie dla {{dataPoint}}",
    "learning_scene_created": "Utworzono scenę \"{{name}}\" z {{count}} punktów danych",
    "learning_association_learned": "Wyuczone powiązanie między {{Primary}} i {{Partner}}",
    "learning_data_saved": "Zapisane dane uczenia się",
    "learning_data_loaded": "Dane uczenia się załadowane ze skojarzeń {{count}}",
    "server_starting": "Uruchamianie narzędzi ...",
    "server_started": "Toolherver zaczął pomyślnie w porcie {{port}}",
    "server_failed_start": "Nie udało się uruchomić narzędzi: {{error}}",
    "server_stopping": "Zatrzymywanie toalerów ...",
    "server_stopped": "Toolerver zatrzymał się",
    "server_already_running": "Toolerserver już działa",
    "server_chat_processed": "Żądanie czatu pomyślnie przetworzone",
    "server_intent_processed": "Przetworzone żądanie intencyjne",
    "vectordb_connection_ok": "Wektorowe połączenie bazy danych",
    "vectordb_connection_failed": "Wektorowe połączenie bazy danych nie powiodło się: {{error}}",
    "vectordb_embedding_generated": "Osadzanie wygenerowane dla {{Text}}",
    "vectordb_data_stored": "Dane przechowywane w bazie danych wektorowych",
    "vectordb_duplicates_cleaned": "Oczyszczone {{Count}} zduplikowane wpisy",
    "vectordb_search_completed": "Wyszukiwanie wektorowe zakończone z wynikami {{count}}",
    "llm_response_generated": "Wygenerowana reakcja LLM",
    "llm_request_failed": "Żądanie LLM nie powiodło się: {{error}}",
    "llm_model_unavailable": "Model LLM niedostępny",
    "llm_intent_analysis_complete": "LLM Intent Analiza zakończona",
    "llm_fallback_parsing": "Korzystanie z parsingu Fallback dla odpowiedzi LLM",
    "llm_fallback_pattern": "Detektor LLM spadł do wykrywania wzoru",
    "llm_error": "Błąd wykrywania LLM: {{błąd}}",
    "llm_configured": "Skonfigurowany detektor LLM",
    "llm_unavailable": "LLM niedostępny: {{error}}",
    "general_initialized": "{{komponent}} zainicjowano pomyślnie",
    "general_configuration_updated": "Zaktualizowano konfigurację",
    "general_error_occurred": "Wystąpił błąd: {{błąd}}",
    "general_operation_complete": "Ukończona operacja",
    "general_invalid_input": "Nieprawidłowe wejście: {{input}}",
    "general_not_available": "{{funkcja}} niedostępna"
}
