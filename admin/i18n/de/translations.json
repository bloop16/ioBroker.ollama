{
    "ollama adapter settings": "Adaptereinstellungen für Ollama",
    "Ollama Server IP": "Ollama Server IP",
    "Ollama Server Port": "Ollama Server Port",
    "Check if Ollama model is running": "Prüfen, ob das Ollama-Modell läuft",
    "Timer to check if the Ollama model is running. Set to 0 to disable.": "Timer zum Prüfen, ob das Ollama-Modell läuft. Auf 0 setzen, um es zu deaktivieren.",
    "Ollama Models": "Ollama-Modelle",
    "Response": "Antwort",
    "Running": "Läuft",
    "Expires": "Läuft ab",
    "Messages": "Nachrichten",
    "Role": "Rolle",
    "Content": "Inhalt",
    "Images (JSON Array)": "Bilder (JSON-Array)",
    "Tool Calls (JSON Array)": "Werkzeugaufrufe (JSON-Array)",
    "Think": "Denken",
    "Tools (JSON)": "Werkzeuge (JSON)",
    "Keep Alive": "Aktiv lassen",
    "Format ('json' or JSON object)": "Format ('json' oder JSON-Objekt)",
    "Options (JSON)": "Optionen (JSON)",
    "Info": "Info",
    "Connection status": "Verbindungsstatus",
    "Vector Database": "Vektordatenbank",
    "Clean up duplicates": "Duplikate bereinigen",
    "Description": "Beschreibung",
    "Units": "Einheiten",
    "Value for TRUE (Boolean)": "Wert für WAHR (Boolean)",
    "Value for FALSE (Boolean)": "Wert für FALSCH (Boolean)",
    "Location": "Standort",
    "Data type": "Datentyp",
    "Select the data type for this datapoint": "Datentyp für diesen Datenpunkt auswählen",
    "Additional text": "Zusätzlicher Text",
    "Additional text for text type": "Zusätzlicher Text für Texttyp",
    "Use Qdrant": "Qdrant verwenden",
    "Qdrant Server IP": "Qdrant Server IP",
    "Qdrant Server Port": "Qdrant Server Port",
    "Database": "Datenbank",
    "Enable Datapoint Control": "Datenpunkt-Steuerung aktivieren",
    "Allow AI models to automatically change datapoints based on their responses (e.g., 'Martin ist jetzt anwesend').": "Erlaubt AI-Modellen automatisch Datenpunkte basierend auf ihren Antworten zu ändern (z.B. 'Martin ist jetzt anwesend').",
    "Control": "Steuerung",
    "Embedding Model": "Embedding-Modell",
    "Max Context Results": "Max. Kontext-Ergebnisse",
    "Allow automatic state changes": "Automatische Statusänderungen erlauben",
    "Boolean": "Boolean",
    "Number": "Zahl",
    "Text": "Text",
    "Processing": "Verarbeitung",
    "Response Content": "Antwortinhalt",
    "Connection": "Verbindung",
    "IP address or hostname of the direct Ollama server (for status monitoring).": "IP -Adresse oder Hostname des direkten Ollama -Servers (zur Statusüberwachung).",
    "Port of the direct Ollama server (default: 11434).": "Port des direkten Ollama -Servers (Standard: 11434).",
    "OpenWebUI Server IP": "OpenWebui Server IP",
    "IP address or hostname of the OpenWebUI server.": "IP -Adresse oder Hostname des OpenWebui -Servers.",
    "OpenWebUI Server Port": "OpenWebui Server -Port",
    "Port of the OpenWebUI server.": "Port des OpenWebui -Servers.",
    "OpenWebUI API Key": "OpenWebui -API -Schlüssel",
    "API Key for OpenWebUI authentication (Bearer Token). Get it from Settings > Account in OpenWebUI.": "API -Schlüssel für die OpenWebui -Authentifizierung (Trägertoken). Holen Sie es aus Einstellungen> Konto in OpenWebui.",
    "Check model status interval": "Überprüfen Sie das Modellstatusintervall",
    "Timer to check model availability via direct Ollama connection. Set to 0 to disable.": "Timer, um die Verfügbarkeit der Modell über direkte Ollama -Verbindung zu überprüfen. Auf 0 einstellen, um zu deaktivieren.",
    "Use Qdrant as vector database for Ollama.": "Verwenden Sie Qdrant als Vektordatenbank für Ollama.",
    "IP address or hostname of the Qdrant server.": "IP -Adresse oder Hostname des QDrant -Servers.",
    "Port of the Qdrant server.": "Port des QDrant -Servers.",
    "Model to use for generating embeddings.": "Modell, das zur Erzeugung von Einbettungen verwendet werden soll.",
    "Maximum number of context results to include in queries.": "Maximale Anzahl der Kontextergebnisse, die in Abfragen enthalten sind.",
    "Function Calling": "Funktionsaufruf",
    "Allow AI models to control ioBroker datapoints via function calls.": "Ermöglichen Sie AI -Modellen, IOBROKER -DataPoints über Funktionsaufrufe zu steuern.",
    "If enabled, AI models can automatically change this datapoint's value based on their responses.": "Wenn AI -Modelle aktiviert sind, können AI -Modelle den Wert dieses Datenpunktes automatisch anhand ihrer Antworten ändern.",
    "Select the data type for this datapoint.": "Wählen Sie den Datentyp für diesen Datenpunkt aus.",
    "Description of the datapoint.": "Beschreibung des Datenpunktes.",
    "Location of the datapoint.": "Ort des Datenpunktes.",
    "Unit of the value (e.g. °C, %, etc.)": "Einheit des Wertes (z. B. ° C, %usw.)",
    "Value used for TRUE.": "Wert verwendet für true.",
    "Value used for FALSE.": "Wert verwendet für false.",
    "Additional text for text type.": "Zusätzlicher Text für Texttyp.",
    "Original Model Name": "Originalmodellname",
    "Temperature": "Temperatur",
    "Controls randomness in AI responses (0.0 = deterministic, 1.0 = very creative)": "Steuert die Zufälligkeit in KI-Antworten (0.0 = deterministisch, 1.0 = sehr kreativ)",
    "Max Tokens": "Max Tokens",
    "Maximum number of tokens in AI response": "Maximale Anzahl von Tokens in der KI-Antwort",
    "Automatic Control Whitelist": "Automatische Steuerungs-Whitelist",
    "Whitelist of command patterns that trigger automatic datapoint control. Use * as wildcard. Separate patterns with | (pipe). Only messages matching these patterns will trigger commands.": "Whitelist von Befehlsmustern, die automatische Datenpunkt-Steuerung auslösen. Verwenden Sie * als Platzhalter. Trennen Sie Muster mit | (Pipe). Nur Nachrichten, die diesen Mustern entsprechen, lösen Befehle aus.",
    "intent_control_detected": "Steuerungsabsicht erkannt",
    "intent_info_detected": "Informationsanfrage erkannt",
    "intent_no_intent": "Keine Absicht erkannt",
    "intent_scene_detected": "Szenen-Aktion erkannt",
    "intent_confidence_low": "Absicht-Vertrauen zu niedrig",
    "datapoint_set_success": "{{datapoint}} erfolgreich auf {{value}} gesetzt",
    "datapoint_set_failed": "Fehler beim Setzen von {{datapoint}}: {{error}}",
    "datapoint_not_allowed": "Datenpunkt {{datapoint}} nicht für automatische Steuerung erlaubt",
    "datapoint_type_conversion_failed": "Typkonvertierung fehlgeschlagen für {{value}} zu {{type}}",
    "datapoint_boolean_true": "wahr",
    "datapoint_boolean_false": "falsch",
    "datapoint_invalid_type": "Ungültiger Datentyp: {{type}}",
    "learning_action_recorded": "Aktion für {{datapoint}} aufgezeichnet",
    "learning_scene_created": "Szene \"{{name}}\" mit {{count}} Datenpunkten erstellt",
    "learning_association_learned": "Assoziation zwischen {{primary}} und {{partner}} gelernt",
    "learning_data_saved": "Lerndaten gespeichert",
    "learning_data_loaded": "Lerndaten mit {{count}} Assoziationen geladen",
    "server_starting": "ToolServer wird gestartet...",
    "server_started": "ToolServer erfolgreich auf Port {{port}} gestartet",
    "server_failed_start": "ToolServer-Start fehlgeschlagen: {{error}}",
    "server_stopping": "ToolServer wird gestoppt...",
    "server_stopped": "ToolServer gestoppt",
    "server_already_running": "ToolServer läuft bereits",
    "server_chat_processed": "Chat-Anfrage erfolgreich verarbeitet",
    "server_intent_processed": "Intent-Anfrage verarbeitet",
    "vectordb_connection_ok": "Vektordatenbank-Verbindung erfolgreich",
    "vectordb_connection_failed": "Vektordatenbank-Verbindung fehlgeschlagen: {{error}}",
    "vectordb_embedding_generated": "Embedding für {{text}} generiert",
    "vectordb_data_stored": "Daten in Vektordatenbank gespeichert",
    "vectordb_duplicates_cleaned": "{{count}} doppelte Einträge bereinigt",
    "vectordb_search_completed": "Vektorsuche mit {{count}} Ergebnissen abgeschlossen",
    "llm_response_generated": "LLM-Antwort generiert",
    "llm_request_failed": "LLM-Anfrage fehlgeschlagen: {{error}}",
    "llm_model_unavailable": "LLM-Modell nicht verfügbar",
    "llm_intent_analysis_complete": "LLM-Intent-Analyse abgeschlossen",
    "llm_fallback_parsing": "Fallback-Parsing für LLM-Antwort verwendet",
    "llm_fallback_pattern": "LLM-Detektor fällt auf Mustererkennung zurück",
    "llm_error": "LLM-Erkennungsfehler: {{error}}",
    "llm_configured": "LLM-Detektor konfiguriert",
    "llm_unavailable": "LLM nicht verfügbar: {{error}}",
    "general_initialized": "{{component}} erfolgreich initialisiert",
    "general_configuration_updated": "Konfiguration aktualisiert",
    "general_error_occurred": "Fehler aufgetreten: {{error}}",
    "general_operation_complete": "Vorgang abgeschlossen",
    "general_invalid_input": "Ungültige Eingabe: {{input}}",
    "general_not_available": "{{feature}} nicht verfügbar"
}
