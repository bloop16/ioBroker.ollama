{
    "ollama adapter settings": "Adapter settings for Ollama",
    "Ollama Server IP": "Ollama Server IP",
    "Ollama Server Port": "Ollama Server Port",
    "Check if Ollama model is running": "Check if Ollama model is running",
    "Timer to check if the Ollama model is running. Set to 0 to disable.": "Timer to check if the Ollama model is running. Set to 0 to disable.",
    "Ollama Models": "Ollama Models",
    "Response": "Response",
    "Running": "Running",
    "Expires": "Expires",
    "Messages": "Messages",
    "Role": "Role",
    "Content": "Content",
    "Images (JSON Array)": "Images (JSON Array)",
    "Tool Calls (JSON Array)": "Tool Calls (JSON Array)",
    "Stream": "Stream",
    "Think": "Think",
    "Tools (JSON)": "Tools (JSON)",
    "Keep Alive": "Keep Alive",
    "Format ('json' or JSON object)": "Format ('json' or JSON object)",
    "Options (JSON)": "Options (JSON)",
    "Info": "Info",
    "Connection status": "Connection status",
    "Description": "Description",
    "Units": "Units",
    "Value for TRUE (Boolean)": "Value for TRUE (Boolean)",
    "Value for FALSE (Boolean)": "Value for FALSE (Boolean)",
    "Location": "Location",
    "Data type": "Data type",
    "Select the data type for this datapoint": "Select the data type for this datapoint",
    "Additional text": "Additional text",
    "Additional text for text type": "Additional text for text type",
    "Use Qdrant": "Use Qdrant",
    "Qdrant Server IP": "Qdrant Server IP",
    "Qdrant Server Port": "Qdrant Server Port",
    "Database": "Database",
    "Enable Datapoint Control": "Enable Datapoint Control",
    "Allow AI models to automatically change datapoints based on their responses (e.g., 'Martin ist jetzt anwesend').": "Allow AI models to automatically change datapoints based on their responses (e.g., 'Martin ist jetzt anwesend').",
    "Control": "Control",
    "Embedding Model": "Embedding Model",
    "Max Context Results": "Max Context Results",
    "Allow automatic state changes": "Allow automatic state changes",
    "Boolean": "Boolean",
    "Number": "Number",
    "Text": "Text",
    "Vector Database": "向量数据库",
    "Clean up duplicates": "清理重复项",
    "Processing": "加工",
    "Response Content": "响应内容",
    "Connection": "联系",
    "IP address or hostname of the direct Ollama server (for status monitoring).": "直接Ollama服务器的IP地址或主机名（用于状态监视）。",
    "Port of the direct Ollama server (default: 11434).": "直接Ollama服务器的端口（默认值：11434）。",
    "OpenWebUI Server IP": "OpenWebui服务器IP",
    "IP address or hostname of the OpenWebUI server.": "IP地址或OpenWebui服务器的主机名。",
    "OpenWebUI Server Port": "OpenWebui服务器端口",
    "Port of the OpenWebUI server.": "OpenWebui服务器的端口。",
    "OpenWebUI API Key": "OpenWebui API键",
    "API Key for OpenWebUI authentication (Bearer Token). Get it from Settings > Account in OpenWebUI.": "openwebui身份验证的API密钥（携带者令牌）。从OpenWebui中的设置>帐户获取它。",
    "Check model status interval": "检查模型状态间隔",
    "Timer to check model availability via direct Ollama connection. Set to 0 to disable.": "计时器通过直接Ollama连接检查模型可用性。设置为0禁用。",
    "Use Qdrant as vector database for Ollama.": "使用QDrant作为Ollama的矢量数据库。",
    "IP address or hostname of the Qdrant server.": "QDRANT服务器的IP地址或主机名。",
    "Port of the Qdrant server.": "QDRANT服务器的端口。",
    "Model to use for generating embeddings.": "用于生成嵌入的模型。",
    "Maximum number of context results to include in queries.": "查询中要包含的上下文结果数量的最大数量。",
    "Function Calling": "函数调用",
    "Allow AI models to control ioBroker datapoints via function calls.": "允许AI模型通过函数调用控制iObroker数据点。",
    "If enabled, AI models can automatically change this datapoint's value based on their responses.": "如果启用，AI模型可以根据其响应自动更改此数据点的值。",
    "Select the data type for this datapoint.": "选择此数据点的数据类型。",
    "Description of the datapoint.": "数据点的描述。",
    "Location of the datapoint.": "数据点的位置。",
    "Unit of the value (e.g. °C, %, etc.)": "值的单位（例如°C，％等）",
    "Value used for TRUE.": "用于true的值。",
    "Value used for FALSE.": "值用于false。",
    "Additional text for text type.": "文本类型的其他文本。",
    "Original Model Name": "原始型号名称",
    "Temperature": "温度",
    "Controls randomness in AI responses (0.0 = deterministic, 1.0 = very creative)": "控制AI响应中的随机性（0.0 =确定性，1.0 =非常有创意）",
    "Max Tokens": "最大令牌",
    "Maximum number of tokens in AI response": "AI响应中的最大令牌数量",
    "Automatic Control Whitelist": "自动控制白名单",
    "Whitelist of command patterns that trigger automatic datapoint control. Use * as wildcard. Separate patterns with | (pipe). Only messages matching these patterns will trigger commands.": "命令模式的白名单触发自动数据点控件。使用 *作为通配符。与|的单独模式（管道）。只有匹配这些模式的消息才会触发命令。",
    "intent_control_detected": "控制意图",
    "intent_info_detected": "检测到的信息请求",
    "intent_no_intent": "没有意图",
    "intent_scene_detected": "场景动作检测到",
    "intent_confidence_low": "意图信心太低",
    "datapoint_set_success": "成功将{{dataPoint}}设置为{{value}}",
    "datapoint_set_failed": "无法设置{{dataPoint}}：{{error}}",
    "datapoint_not_allowed": "DataPoint {{datapoint}}不允许自动控制",
    "datapoint_type_conversion_failed": "类型转换失败{{value}} to {{type}}",
    "datapoint_boolean_true": "真的",
    "datapoint_boolean_false": "错误的",
    "datapoint_invalid_type": "无效数据类型：{{type}}",
    "learning_action_recorded": "{{datapoint}}的记录动作",
    "learning_scene_created": "创建的场景“ {{name}}”与{{count}} datapoints",
    "learning_association_learned": "{{primary}}和{{partern}}之间学到的关联",
    "learning_data_saved": "学习保存的数据",
    "learning_data_loaded": "学习{{count}}关联加载的数据",
    "server_starting": "启动Toolserver ...",
    "server_started": "Toolserver在端口{{port}}上成功开始",
    "server_failed_start": "无法启动工具服务器：{{error}}",
    "server_stopping": "停止工具服务器...",
    "server_stopped": "Toolserver停止了",
    "server_already_running": "工具服务器已经在运行",
    "server_chat_processed": "聊天请求成功处理",
    "server_intent_processed": "处理意图请求",
    "vectordb_connection_ok": "向量数据库连接成功",
    "vectordb_connection_failed": "矢量数据库连接失败：{{error}}",
    "vectordb_embedding_generated": "嵌入为{{text}}生成的生成",
    "vectordb_data_stored": "存储在矢量数据库中的数据",
    "vectordb_duplicates_cleaned": "清洁{{{count}}重复条目",
    "vectordb_search_completed": "vector搜索以{{count}}结果完成",
    "llm_response_generated": "LLM响应生成",
    "llm_request_failed": "LLM请求失败：{{error}}",
    "llm_model_unavailable": "LLM模型不可用",
    "llm_intent_analysis_complete": "LLM意图分析完成",
    "llm_fallback_parsing": "将后备解析用于LLM响应",
    "llm_fallback_pattern": "LLM检测器落后于模式检测",
    "llm_error": "LLM检测错误：{{error}}",
    "llm_configured": "LLM检测器配置",
    "llm_unavailable": "LLM不可用：{{error}}",
    "general_initialized": "{{component}}成功初始化",
    "general_configuration_updated": "配置更新",
    "general_error_occurred": "发生错误：{{error}}",
    "general_operation_complete": "操作完成",
    "general_invalid_input": "无效输入：{{input}}",
    "general_not_available": "{{feature}}不可用"
}
