{
    "ollama adapter settings": "Adapter settings for Ollama",
    "Ollama Server IP": "Ollama Server IP",
    "Ollama Server Port": "Ollama Server Port",
    "Check if Ollama model is running": "Check if Ollama model is running",
    "Timer to check if the Ollama model is running. Set to 0 to disable.": "Timer to check if the Ollama model is running. Set to 0 to disable.",
    "Ollama Models": "Ollama Models",
    "Response": "Response",
    "Running": "Running",
    "Expires": "Expires",
    "Messages": "Messages",
    "Role": "Role",
    "Content": "Content",
    "Images (JSON Array)": "Images (JSON Array)",
    "Tool Calls (JSON Array)": "Tool Calls (JSON Array)",
    "Stream": "Stream",
    "Think": "Think",
    "Tools (JSON)": "Tools (JSON)",
    "Keep Alive": "Keep Alive",
    "Format ('json' or JSON object)": "Format ('json' or JSON object)",
    "Options (JSON)": "Options (JSON)",
    "Info": "Info",
    "Connection status": "Connection status",
    "Description": "Description",
    "Units": "Units",
    "Value for TRUE (Boolean)": "Value for TRUE (Boolean)",
    "Value for FALSE (Boolean)": "Value for FALSE (Boolean)",
    "Location": "Location",
    "Data type": "Data type",
    "Select the data type for this datapoint": "Select the data type for this datapoint",
    "Additional text": "Additional text",
    "Additional text for text type": "Additional text for text type",
    "Use Qdrant": "Use Qdrant",
    "Qdrant Server IP": "Qdrant Server IP",
    "Qdrant Server Port": "Qdrant Server Port",
    "Database": "Database",
    "Enable Datapoint Control": "Enable Datapoint Control",
    "Allow AI models to automatically change datapoints based on their responses (e.g., 'Martin ist jetzt anwesend').": "Allow AI models to automatically change datapoints based on their responses (e.g., 'Martin ist jetzt anwesend').",
    "Control": "Control",
    "Embedding Model": "Embedding Model",
    "Max Context Results": "Max Context Results",
    "Allow automatic state changes": "Allow automatic state changes",
    "Boolean": "Boolean",
    "Number": "Number",
    "Text": "Text",
    "Vector Database": "Vectordatabase",
    "Clean up duplicates": "Duplicaten opruimen",
    "Processing": "Verwerking",
    "Response Content": "Reactie -inhoud",
    "Connection": "Verbinding",
    "IP address or hostname of the direct Ollama server (for status monitoring).": "IP -adres of hostnaam van de Direct Ollama Server (voor statusbewaking).",
    "Port of the direct Ollama server (default: 11434).": "Poort van de Direct Ollama Server (standaard: 11434).",
    "OpenWebUI Server IP": "OpenWebui Server IP",
    "IP address or hostname of the OpenWebUI server.": "IP -adres of hostnaam van de OpenWebui -server.",
    "OpenWebUI Server Port": "OpenWebui Server -poort",
    "Port of the OpenWebUI server.": "Poort van de OpenWebui -server.",
    "OpenWebUI API Key": "OpenWebui API -sleutel",
    "API Key for OpenWebUI authentication (Bearer Token). Get it from Settings > Account in OpenWebUI.": "API -sleutel voor OpenWebUI -authenticatie (drager -token). Haal het van instellingen> account in OpenWebui.",
    "Check model status interval": "Controleer het modelstatusinterval",
    "Timer to check model availability via direct Ollama connection. Set to 0 to disable.": "Timer om de beschikbaarheid van het model te controleren via directe Ollama -verbinding. Ingesteld op 0 om uit te schakelen.",
    "Use Qdrant as vector database for Ollama.": "Gebruik Qdrant als vectordatabase voor Ollama.",
    "IP address or hostname of the Qdrant server.": "IP -adres of hostnaam van de Qdrant -server.",
    "Port of the Qdrant server.": "Poort van de Qdrant -server.",
    "Model to use for generating embeddings.": "Model om te gebruiken voor het genereren van inbeddings.",
    "Maximum number of context results to include in queries.": "Maximaal aantal contextresultaten dat moet worden opgenomen in vragen.",
    "Function Calling": "Functie aanroepen",
    "Allow AI models to control ioBroker datapoints via function calls.": "Sta AI -modellen toe om iObroker Datapoints te besturen via functieaanroepen.",
    "If enabled, AI models can automatically change this datapoint's value based on their responses.": "Indien ingeschakeld, kunnen AI -modellen automatisch de waarde van dit Datapoint wijzigen op basis van hun antwoorden.",
    "Select the data type for this datapoint.": "Selecteer het gegevenstype voor dit datapunt.",
    "Description of the datapoint.": "Beschrijving van het DataPoint.",
    "Location of the datapoint.": "Locatie van het Datapoint.",
    "Unit of the value (e.g. °C, %, etc.)": "Eenheid van de waarde (bijv. ° C, %, enz.)",
    "Value used for TRUE.": "Waarde gebruikt voor waar.",
    "Value used for FALSE.": "Waarde gebruikt voor false.",
    "Additional text for text type.": "Extra tekst voor teksttype.",
    "Original Model Name": "Originele modelnaam",
    "Temperature": "Temperatuur",
    "Controls randomness in AI responses (0.0 = deterministic, 1.0 = very creative)": "Controleert willekeur in AI -reacties (0,0 = deterministisch, 1.0 = zeer creatief)",
    "Max Tokens": "Max tokens",
    "Maximum number of tokens in AI response": "Maximaal aantal tokens in AI -reactie",
    "Automatic Control Whitelist": "Automatische besturingshaak",
    "Whitelist of command patterns that trigger automatic datapoint control. Use * as wildcard. Separate patterns with | (pipe). Only messages matching these patterns will trigger commands.": "Whitelist van opdrachtpatronen die automatische datapoint -besturingselement activeren. Gebruik * als wildcard. Afzonderlijke patronen met | (pijp). Alleen berichten die overeenkomen met deze patronen zullen opdrachten activeren.",
    "intent_control_detected": "Controle -intentie gedetecteerd",
    "intent_info_detected": "Informatieverzoek gedetecteerd",
    "intent_no_intent": "Geen intentie herkend",
    "intent_scene_detected": "Scène -actie gedetecteerd",
    "intent_confidence_low": "Intentie vertrouwen te laag",
    "datapoint_set_success": "Set met succes {{datapoint}} op {{waarde}}",
    "datapoint_set_failed": "Kan niet {{datapoint}} instellen: {{error}}",
    "datapoint_not_allowed": "Datapoint {{Datapoint}} niet toegestaan voor automatische besturingselement",
    "datapoint_type_conversion_failed": "Type conversie mislukt voor {{waarde}} tot {{type}}",
    "datapoint_boolean_true": "WAAR",
    "datapoint_boolean_false": "vals",
    "datapoint_invalid_type": "Ongeldig gegevenstype: {{Type}}",
    "learning_action_recorded": "Opgenomen actie voor {{datapoint}}",
    "learning_scene_created": "Scène gemaakt \"{{name}}\" met {{count}} datapoints",
    "learning_association_learned": "Geleerde associatie tussen {{primary}} en {{Partner}}",
    "learning_data_saved": "Leergegevens opgeslagen",
    "learning_data_loaded": "Leergegevens geladen met {{count}} associaties",
    "server_starting": "Start toolserver ...",
    "server_started": "Toolserver gestart met succes op poort {{Port}}",
    "server_failed_start": "Niet starten om ToolsRver te starten: {{error}}",
    "server_stopping": "Stop Toolserver ...",
    "server_stopped": "Toolserver gestopt",
    "server_already_running": "Toolserver loopt al aan",
    "server_chat_processed": "Chatverzoek met succes verwerkt",
    "server_intent_processed": "Intentieverzoek verwerkt",
    "vectordb_connection_ok": "Vector Database -verbinding succesvol",
    "vectordb_connection_failed": "Vector Database -verbinding is mislukt: {{error}}",
    "vectordb_embedding_generated": "Inbedding gegenereerd voor {{text}}",
    "vectordb_data_stored": "Gegevens opgeslagen in vectordatabase",
    "vectordb_duplicates_cleaned": "Schoongemaakte {{count}} dubbele vermeldingen",
    "vectordb_search_completed": "Vector -zoekopdracht voltooid met {{count}} resultaten",
    "llm_response_generated": "LLM -reactie gegenereerd",
    "llm_request_failed": "LLM -verzoek is mislukt: {{error}}",
    "llm_model_unavailable": "LLM -model niet beschikbaar",
    "llm_intent_analysis_complete": "LLM intentanalyse compleet",
    "llm_fallback_parsing": "Met behulp van Fallback Parsing voor LLM -reactie",
    "llm_fallback_pattern": "LLM -detector valt terug naar patroondetectie",
    "llm_error": "LLM Detectiefout: {{error}}",
    "llm_configured": "LLM -detector geconfigureerd",
    "llm_unavailable": "Llm niet beschikbaar: {{error}}",
    "general_initialized": "{{component}} met succes geïnitialiseerd",
    "general_configuration_updated": "Configuratie bijgewerkt",
    "general_error_occurred": "Er is een fout opgetreden: {{error}}",
    "general_operation_complete": "Bewerking voltooid",
    "general_invalid_input": "Ongeldige invoer: {{input}}",
    "general_not_available": "{{functie}} niet beschikbaar"
}
